function M = MDP()
% This functions returns the MDP model for the simple grid world.
% To define the MDP model, replace the "???" all over the file by the 
% proper values.
init;

% Number of states of the robot:
nX = ???;

% Number of actions available to the robot:
nU = ???;

% Initial state distribution. This a vector which indicates the probability of
% starting in a given state, for each state. Recall that our robot will always
% start in state 1. Fill in the corresponding probabilities.

% state:  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16
P0 =   [??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???];

% Transition probabilities matrix. For each of the 5 actions fill in the
% corresponding transition probability matrix.
% For example, P(2, N, 1) represents the probability of moving to state 1
% from state 2 when choosing action N.

% Transition probabilities for action N. Lines correspond to the "current"
% state and columns to the "next" state.

% Final state:  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16             

P(:, N, :) = [1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  1
              1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  2
              0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  3
              0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  4
              0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  5
              0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  6
              0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  7
              0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  8
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state:  9
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state: 10
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0;... % Initial state: 11
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0;... % Initial state: 12
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0;... % Initial state: 13
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0;... % Initial state: 14
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0;... % Initial state: 15
              0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0];   % Initial state: 16

% Transition probabilities for action S. Lines correspond to the "current"
% state and columns to the "next" state.

% Final state:  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16             

P(:, S, :) = [??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  1
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  2
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  3
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  4
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  5
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  6
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  7
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  8
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  9
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 10
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 11
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 12
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 13
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 14
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 15
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???];   % Initial state: 16

% Transition probabilities for action E. Lines correspond to the "current"
% state and columns to the "next" state.

% Final state:  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16             

P(:, E, :) = [??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  1
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  2
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  3
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  4
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  5
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  6
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  7
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  8
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  9
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 10
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 11
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 12
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 13
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 14
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 15
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???];   % Initial state: 16
          
% Transition probabilities for action W. Lines correspond to the "current"
% state and columns to the "next" state.

% Final state:  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16             

P(:, W, :) = [??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  1
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  2
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  3
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  4
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  5
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  6
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  7
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  8
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  9
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 10
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 11
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 12
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 13
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 14
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 15
              ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???];   % Initial state: 16

% Transition probabilities for action NoOp. Lines correspond to the "current"
% state and columns to the "next" state.

% Final state:     1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16             

P(:, NoOp, :) = [??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  1
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  2
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  3
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  4
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  5
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  6
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  7
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  8
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state:  9
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 10
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 11
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 12
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 13
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 14
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???;... % Initial state: 15
                 ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???];   % Initial state: 16
             
% Reward function, reprensented as a state x action matrix. r(2, N) represents
% the reward of choosing action N in state 2.
% Here, we choose to set the reward of the goal (being in state 16 and not
% moving) to 1., and 0. for all the other state and action

% Action:   N    S    E    W  NoOp

r       = [???  ???  ???  ???  ???;... % State:  1
           ???  ???  ???  ???  ???;... % State:  2
           ???  ???  ???  ???  ???;... % State:  3
           ???  ???  ???  ???  ???;... % State:  4
           ???  ???  ???  ???  ???;... % State:  5
           ???  ???  ???  ???  ???;... % State:  6
           ???  ???  ???  ???  ???;... % State:  7
           ???  ???  ???  ???  ???;... % State:  8
           ???  ???  ???  ???  ???;... % State:  9
           ???  ???  ???  ???  ???;... % State: 10
           ???  ???  ???  ???  ???;... % State: 11
           ???  ???  ???  ???  ???;... % State: 12
           ???  ???  ???  ???  ???;... % State: 13
           ???  ???  ???  ???  ???;... % State: 14
           ???  ???  ???  ???  ???;... % State: 15
           ???  ???  ???  ???  ???];   % State: 16

% Discount factor. We will take it always to be 0.95.
      
gamma = 0.95;

% We now create a structure that stores all the elements of the MDP
M = struct('nX', nX, 'nU', nU, 'P0', P0, 'P', P, 'r', r, 'gamma', gamma);
